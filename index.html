<!DOCTYPE html>
<html>

<head>
  <meta name="viewport" content="width=device-width">
  <link rel="stylesheet" href="style.css">  
</head>

<body>
 
<div class="header">
  <name> 
    <span style="font-weight: bold;">
      Topics in Games, Learning, and Optimization
    </span>
    <br>
    <span style="font-size: 16px">SUTD 40.616 -- Fall 2025</span>
  </name>  
  <div class="header-bar"></div>
</div>

<h2>Course Description</h2>
Graduate-level course on learning in games.
More information coming soon...

<br>
<br>
<img src="mwu-fig.png" text-align="center" style="width:95%; text-align: center">
<br>
<br>

<b>Co-instructors</b>: Anas Barakat, John Lazarsfeld, Joseph Sakos. <br>
<b>Contact</b>: sutd.lgo.course@gmail.com <br>
<b>Time</b>: Tues/Thurs, 10am-12pm SGT <br>
<b>Location</b>: TBD

<br><br>
<i>To access a Zoom link and lecture recordings,
please email jlazarsfeld@gmail.com</i>


<br><br>
<h2>Schedule</h2>

<p>Part I: Online Learning</p>

<ul>
  <li>
    <span style="color: #002499">
      Lecture 01: 
      Introduction to Online Learning
    </span>
    -- (2025.09.16)
    
    <br>
    <i>
      Prediction with expert advice;
      online convex optimization;
      external regret;
      Multiplicative Weights Update
      and Online Gradient Descent algorithms. 
    </i>
    <br>
    <a href=".">[notes pdf]</a>
  </li>
  <li>
    <span style="color: #002499">
    Lecture 02:
    Algorithms for Online Learning, Part I
    </span>
    -- (2025.09.18)
    <br>
    <i>
      Follow-the-Regularized-Leader family;
      MWU as FTRL with entropic regularization;
      Minimax lower bounds for online learning.
    </i>
  </li>
  <li>
    <span style="color: #002499">
      Lecture 03: 
      Algorithms for Online Learning, Part II
    </span>
    -- (2025.09.23)
    <br>
    <i>
      Online Mirror Descent; Follow-the-Perturbed-Leader;
      Beyond \sqrt{T} regret: strongly convex
      and exp-concave losses. 
    </i>
  </li>

  <li>
    <span style="color: #002499">
      Lecture 04: 
      Online Learning with Bandit Feedback
    </span>
    -- (2025.09.25)
    <br>
    <i>
      Adversarial bandits and the EXP3 algorithm;
      Stochastic bandits and the Explore-then-Commit
      and UCB algorithms. 
    </i>
    
  <li>
    <span style="color: #002499">
      Lecture 05: 
      Phi-Regret Minimization
    </span>
    -- (2025.09.30)
    <br>
    <i>
      Beyond external regret:
      swap-regret, internal-regret, and the
      Phi-Regret-minimization framework. 
    </i>
  </li>

  <li>
    <span style="color: #002499">
      Lecture 06: 
      Blackwell Approachability and Regret Matching
    </span>
    -- (2025.10.02)
    <br>
    <i>
    </i>
  </li>

</ul>

<hr>

<p>Part II: Learning in Games (Normal Form and Markov Games)</p>

<ul>
  <li>
    <span style="color: #002499">
      Lecture 07:
      Introduction to Game Theory
    </span>
    -- (2025.10.07)
    <br>
    <i>
      Normal-Form Games, Nash Equilibria,
      and Game Classes.
    </i>
  </li>

  <li>
    ...
  </li>

</ul>

<hr>

<p>Part III: Learning in Games (Extensive Form and Continuous Games) </p>

<ul>
  <li>
    <span style="color: #002499">
      Lecture 13:
      Introduction to Extensive-Form Games
    </span>
    -- (2025.11.04)
    <br>
    <i>
    </i>
  </li>

  <li>
    ...
  </li>
  
</ul>


<br>

<h2>Resources</h2>


<br><br><br><br>
<em>Last Updated: 2025.09.08</em>
<br><br><br><br><br><br><br><br>

</body>
</html>
